## Overview

The main objective of this code is to understand the underlying components of neural network. This is quite a limited neural network that hopes to improve over time with more features. Below are the available features so far:
  - Optimizer: Gradient Descent
  - Activation Functions:
    - Sigmoid
    - Tanh
    - Relu
  - Initialization: Normalized Xavier Weight Initialization
  - Loss function: MSE

## Installation

Clone this git repository to your local workspace.
`git clone https://github.com/fucheng96/neural-net.git`
